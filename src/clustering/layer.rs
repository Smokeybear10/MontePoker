use crate::cards::observation::NodeObservation;
use crate::cards::street::Street;
use crate::clustering::abstraction::NodeAbstraction;
use crate::clustering::consumer::Consumer;
use crate::clustering::histogram::Histogram;
use crate::clustering::metric::Metric;
use crate::clustering::producer::Producer;
use crate::clustering::progress::Progress;
use crate::clustering::projection::Projection;
use crate::clustering::xor::Pair;
use std::collections::BTreeMap;
use std::io::Read;
use std::sync::Arc;

/// KMeans hiearchical clustering. Every Observation is to be clustered with "similar" observations. River cards are the base case, where similarity metric is defined by equity. For each higher layer, we compare distributions of next-layer outcomes. Distances are measured by EMD and unsupervised kmeans clustering is used to cluster similar distributions. Potential-aware imperfect recall!
pub struct Layer {
    street: Street,
    metric: BTreeMap<Pair, f32>, // impl Metric
    distributions: BTreeMap<NodeObservation, (Histogram, NodeAbstraction)>, // impl Projection
    kabstractions: BTreeMap<NodeAbstraction, (Histogram, Histogram)>,
}

impl Layer {
    /// Yield the next layer of abstraction by kmeans clustering. The recursive nature of layer methods encapsulates the hiearchy of learned abstractions via kmeans.
    /// TODO; make this async and persist to database after each layer
    pub fn inner(&self) -> Self {
        let inner = Self {
            street: self.inner_street(),
            metric: self.inner_metric(),
            kabstractions: self.inner_kmeans(),
            distributions: self.inner_points(),
        };
        inner.kmeans()
    }

    /// async equity calculations to create initial River layer.
    pub async fn outer() -> Self {
        Self {
            street: Street::Rive,
            metric: Self::outer_metric(),
            kabstractions: BTreeMap::default(),
            distributions: Self::outer_points().await,
        }
    }
    /// Write to file. We'll open a new file for each layer, whatever.
    pub fn upload(self) -> Self {
        println!("writing layer {}", self.street);
        self.truncate();
        self.upload_distance();
        self.upload_centroid();
        self
    }

    /// Number of centroids in k means on inner layer. Loosely speaking, the size of our abstraction space.
    fn k(&self) -> usize {
        match self.street.prev() {
            Street::Turn => 500,
            Street::Flop => 500,
            Street::Pref => 169,
            _ => unreachable!("no other prev"),
        }
    }

    /// Number of kmeans iterations to run on current layer.
    fn t(&self) -> usize {
        match self.street.prev() {
            Street::Turn => 100,
            Street::Flop => 100,
            Street::Pref => 10,
            _ => unreachable!("no other prev"),
        }
    }

    /// Run kmeans iterations.
    /// Presumably, we have been generated by a previous layer, with the exception of Outer == River.
    /// After the base case, we trust that our observations, abstractions, and metric are correctly populated.
    fn kmeans(self) -> Self {
        assert!(self.kabstractions.len() >= self.k());
        println!("clustering kmeans {} < {}", self.street.prev(), self.street);
        let t = self.t();
        let mut layer = self;
        let ref mut progress = Progress::new(t, 10);
        for _ in 0..t {
            for observation in layer
                .distributions
                .keys()
                .copied()
                .into_iter()
                .collect::<Vec<_>>()
                .iter()
            {
                let ref neighbor = layer.neighbor(observation);
                layer.assign(observation, neighbor);
                layer.absorb(observation, neighbor);
            }
            layer.recycle();
            progress.tick();
        }
        layer
    }

    /// find the nearest neighbor for a given observation
    /// returns the node abstraction that is closest to the observation
    fn neighbor(&self, observation: &NodeObservation) -> NodeAbstraction {
        let mut nearests = f32::MAX;
        let mut neighbor = NodeAbstraction::default();
        let ref histogram = self
            .distributions
            .get(observation)
            .expect("in continuations")
            .0;
        for (centroid, (average, _)) in self.kabstractions.iter() {
            let distance = self.metric.emd(average, histogram);
            if distance < nearests {
                nearests = distance;
                neighbor = centroid.to_owned();
            }
        }
        neighbor
    }

    /// assign the given observation to the specified neighbor
    /// by updating self.distributions mapping
    /// on each iteration, we update the abstraction of the observation
    fn assign(&mut self, observation: &NodeObservation, neighbor: &NodeAbstraction) {
        self.distributions
            .get_mut(observation)
            .expect("in continuations")
            .1 = neighbor.to_owned();
    }

    /// absorb the observation into the specified neighbor
    /// by updating self.kabstractions mapping
    /// we only update the .1 Histogram which is NOT used to calculate kmeans
    /// for everyone else on this iteration.
    /// they get swapped and cleared on the next iteration.
    fn absorb(&mut self, observation: &NodeObservation, neighbor: &NodeAbstraction) {
        let ref children = self
            .distributions
            .get(observation)
            .expect("in continuations")
            .0;
        self.kabstractions
            .get_mut(neighbor)
            .expect("kabstractions was initialized with neighbor")
            .1
            .absorb(children);
    }

    /// forget the old centroids and clear the new ones
    /// basically recylce memory between iterations
    /// out with the old and in with the new
    fn recycle(&mut self) {
        for (_, (old, new)) in self.kabstractions.iter_mut() {
            std::mem::swap(old, new);
            new.destroy();
        }
    }

    fn inner_street(&self) -> Street {
        self.street.prev()
    }

    /// Compute the metric of the next innermost layer. Take outer product of centroid histograms over measure.
    fn inner_metric(&self) -> BTreeMap<Pair, f32> {
        println!("computing metric {} < {}", self.street.prev(), self.street);
        let ref centroids = self.kabstractions;
        let mut metric = BTreeMap::new();
        for (i, (x, _)) in centroids.iter().enumerate() {
            for (j, (y, _)) in centroids.iter().enumerate() {
                if i > j {
                    let index = Pair::from((x, y));
                    let ref x = centroids.get(x).expect("in centroids").0;
                    let ref y = centroids.get(y).expect("in centroids").0;
                    let distance = self.metric.emd(x, y);
                    metric.insert(index, distance);
                }
            }
        }
        metric
    }

    /// Generate all possible obersvations of the next innermost layer.
    /// Assign them to arbitrary abstractions. They will be overwritten during kmeans iterations.
    /// Base case is River which comes from equity bucket calculation.
    fn inner_points(&self) -> BTreeMap<NodeObservation, (Histogram, NodeAbstraction)> {
        println!("projecting {} >> on >> {}", self.street, self.street.prev(),);
        NodeObservation::all(self.street.prev())
            .into_iter()
            .map(|inner| {
                (
                    inner,
                    (
                        self.distributions.project(inner),
                        NodeAbstraction::default(),
                    ),
                )
            })
            .collect()
    }

    /// K Means++ implementation yields initial histograms
    /// Abstraction labels are random and require uniqueness.
    fn inner_kmeans(&self) -> BTreeMap<NodeAbstraction, (Histogram, Histogram)> {
        println!("cluster {} >> into >> {}", self.street, self.street.prev());
        use rand::distributions::Distribution;
        use rand::distributions::WeightedIndex;
        use rand::seq::SliceRandom;
        use rand::SeedableRng;
        // 0. Initialize data structures
        // 1. Choose 1st centroid randomly from the dataset
        let mut centroids = Vec::new();
        let ref mut rng = rand::rngs::StdRng::seed_from_u64(self.street as u64);
        centroids.push(
            self.distributions
                .values()
                .map(|(hist, _)| hist)
                .collect::<Vec<&Histogram>>()
                .choose(rng)
                .cloned()
                .cloned()
                .expect("non-empty lower observations"),
        );
        // 2. Choose nth centroid with probability proportional to squared distance of nearest neighbors
        while centroids.len() < self.k() {
            let ref mut centroids = centroids;
            let weights = self
                .distributions
                .values()
                .map(|(hist, _)| hist)
                .map(|histogram| self.proximity(centroids, histogram))
                .map(|min| min * min)
                .collect::<Vec<f32>>();
            let choice = WeightedIndex::new(weights)
                .expect("valid weights array")
                .sample(rng);
            let sample = self
                .distributions
                .values()
                .map(|(hist, _)| hist)
                .nth(choice)
                .expect("shared index with lowers")
                .to_owned();
            centroids.push(sample);
        }
        // 3. Collect histograms and label with arbitrary (random) Abstractions
        centroids
            .into_iter()
            .map(|mean| (NodeAbstraction::random(), (mean, Histogram::default())))
            .collect::<BTreeMap<_, _>>()
    }

    /// Find the minimum distance between a histogram and
    /// a list of already existing centroids
    /// for k means ++ initialization
    fn proximity(&self, centroids: &Vec<Histogram>, x: &Histogram) -> f32 {
        centroids
            .iter()
            .map(|mean| self.metric.emd(mean, x))
            .min_by(|a, b| a.partial_cmp(b).unwrap())
            .expect("find minimum")
    }

    /// Generate the  baseline metric between equity bucket abstractions. Keeping the u64->f32 conversion is fine for distance since it preserves distance
    pub fn outer_metric() -> BTreeMap<Pair, f32> {
        // println!("calculating equity bucket metric");
        let mut metric = BTreeMap::new();
        for i in 1..=NodeAbstraction::N as u64 {
            for j in i..=NodeAbstraction::N as u64 {
                let distance = (j - i) as f32;
                // it could be interesting to make this quadratic...
                // kinda like E[ equity^2 ] metric
                // but only for Turn <: River projections
                // more interestingly, it may capture the idea of
                // "1% edge over your opponent means
                // more in the ~99% regime
                // than in the ~1% regime"
                let ref i = NodeAbstraction::from(i);
                let ref j = NodeAbstraction::from(j);
                let index = Pair::from((i, j));
                metric.insert(index, distance);
            }
        }
        metric
    }

    // construct observation -> abstraction map via equity calculations
    async fn outer_points() -> BTreeMap<NodeObservation, (Histogram, NodeAbstraction)> {
        println!("calculating equity bucket observations");
        let ref observations = Arc::new(NodeObservation::all(Street::Rive));
        let (tx, rx) = tokio::sync::mpsc::channel::<(NodeObservation, NodeAbstraction)>(1024);
        let consumer = Consumer::new(rx);
        let consumer = tokio::spawn(consumer.run());
        let producers = (0..num_cpus::get())
            .map(|i| Producer::new(i, tx.clone(), observations.clone()))
            .map(|p| tokio::spawn(p.run()))
            .collect::<Vec<_>>();
        std::mem::drop(tx);
        futures::future::join_all(producers).await;
        consumer.await.expect("equity mapping task completes")
    }
}

/*
persistence methods
*/
const BUFFER: usize = 1024 * 1024 * 1024;
impl Layer {
    /// Truncate the files
    fn truncate(&self) {
        std::fs::remove_file(format!("centroid_{}.bin", self.street)).ok();
        std::fs::remove_file(format!("distance_{}.bin", self.street)).ok();
    }

    /// Write centroid data to a file
    fn upload_centroid(&self) {
        let mut file =
            std::fs::File::create(format!("centroid_{}.bin", self.street)).expect("create file");
        let mut progress = Progress::new(self.distributions.len(), 10_000_000);
        for (observation, (_, abstraction)) in self.distributions.iter() {
            use std::io::Write;
            let obs = i64::from(*observation) as u64;
            let abs = i64::from(*abstraction) as u64;
            let ref bytes = [obs.to_le_bytes(), abs.to_le_bytes()].concat();
            file.write_all(bytes).expect("write to file");
            progress.tick();
        }
    }

    /// Write distance data to a file
    fn upload_distance(&self) {
        let mut file =
            std::fs::File::create(format!("distance_{}.bin", self.street)).expect("create file");
        let mut progress = Progress::new(self.metric.len(), 1_000);
        for (pair, distance) in self.metric.iter() {
            use std::io::Write;
            let pair = i64::from(*pair) as u64;
            let distance = f64::from(*distance);
            let ref bytes = [pair.to_le_bytes(), distance.to_le_bytes()].concat();
            file.write_all(bytes).expect("write to file");
            progress.tick();
        }
    }

    /// read centroid data from a file
    pub fn download_centroid(street: Street) -> BTreeMap<NodeObservation, NodeAbstraction> {
        let mut map = BTreeMap::new();
        let file = std::fs::File::open(format!("centroid_{}.bin", street)).expect("file open");
        let ref mut reader = std::io::BufReader::with_capacity(BUFFER, file);
        let ref mut buffer = [0u8; 16];
        while reader.read_exact(buffer).is_ok() {
            let obs_u64 = u64::from_le_bytes(buffer[0..8].try_into().unwrap());
            let abs_u64 = u64::from_le_bytes(buffer[8..16].try_into().unwrap());
            let observation = NodeObservation::from(obs_u64 as i64);
            let abstraction = NodeAbstraction::from(abs_u64 as i64);
            map.insert(observation, abstraction);
        }
        map
    }

    /// read distance data from a file
    pub fn download_distance(street: Street) -> BTreeMap<Pair, f32> {
        let mut map = BTreeMap::new();
        let file = std::fs::File::open(format!("distance_{}.bin", street)).expect("file open");
        let ref mut reader = std::io::BufReader::with_capacity(BUFFER, file);
        let ref mut buffer = [0u8; 12];
        while reader.read_exact(buffer).is_ok() {
            let pair_u64 = u64::from_le_bytes(buffer[0..08].try_into().unwrap());
            let dist_f64 = f64::from_le_bytes(buffer[8..16].try_into().unwrap());
            let pair = Pair::from(pair_u64 as i64);
            let distance = dist_f64 as f32;
            map.insert(pair, distance);
        }
        map
    }
}
