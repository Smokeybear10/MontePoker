use super::histogram::Histogram;
use super::metric::Metric;
use super::projection::Projection;
use super::xor::Pair;
use crate::cards::observation::Observation;
use crate::cards::street::Street;
use crate::clustering::abstraction::Abstraction;
use crate::clustering::bottom::consumer::Consumer;
use crate::clustering::bottom::producer::Producer;
use crate::clustering::bottom::progress::Progress;
use std::collections::HashMap;
use std::sync::Arc;

pub struct Layer {
    street: Street,
    pub(super) metric: HashMap<Pair, f32>,
    pub(super) observations: HashMap<Observation, (Histogram, Abstraction)>,
    abstractions: HashMap<Abstraction, (Histogram, Histogram)>,
}

impl Layer {
    /// async download from database to create initial River layer.
    pub async fn bottom() -> Self {
        let layer = Self {
            street: Street::Rive,
            metric: Self::bottom_metric(),
            observations: Self::bottom_observations().await,
            abstractions: HashMap::default(),
        };
        layer.upload().await;
        layer
    }

    /// Yield the next layer of abstraction by kmeans clustering
    /// TODO; make this async and persist to database after each layer
    pub async fn lift(self) -> Self {
        let mut layer = Self {
            street: self.street.prev(),
            metric: self.lift_metric(),
            observations: self.lift_observations(),
            abstractions: self.lift_abstractions(),
        };
        layer.kmeans(100);
        layer.upload().await;
        layer
    }

    /// Run kmeans iterations.
    /// Presumably, we have been generated by a previous layer, with the exception of Bottom == River.
    /// After the base case, we trust that our observations, abstractions, and metric are correctly populated.
    fn kmeans(&mut self, iterations: usize) {
        for _ in 0..iterations {
            for (_, (data, last)) in self.observations.iter_mut() {
                let mut nearests = f32::MAX;
                let mut neighbor = Abstraction::default();
                for (abstraction, (mean, _)) in self.abstractions.iter_mut() {
                    let distance = self.metric.emd(data, mean);
                    if distance < nearests {
                        nearests = distance;
                        neighbor = abstraction.clone();
                    }
                }
                self.abstractions
                    .get_mut(&neighbor)
                    .expect("key from iteration, not default")
                    .0
                    .absorb(data);
                let _ = std::mem::replace(last, neighbor);
            }
        }
    }

    /// Calculate and return the metric using EMD distances between abstractions
    fn lift_metric(&self) -> HashMap<Pair, f32> {
        let ref centroids = self.abstractions;
        let mut metric = HashMap::new();
        for (i, (x, _)) in centroids.iter().enumerate() {
            for (j, (y, _)) in centroids.iter().enumerate() {
                if i > j {
                    let index = Pair::from((x, y));
                    let ref x = centroids.get(x).expect("kmeans histogram").0;
                    let ref y = centroids.get(y).expect("kmeans histogram").0;
                    let distance = self.metric.emd(x, y);
                    metric.insert(index, distance);
                }
            }
        }
        metric
    }

    /// Generate all possible obersvations. Assign them to arbitrary abstractions. They will be overwritten during kmeans iterations. We start from River which comes from database from equity abstractions.
    #[rustfmt::skip]
    fn lift_observations(&self) -> HashMap<Observation, (Histogram, Abstraction)> {
        Observation::all(self.street.prev())
            .into_iter()
            .map(|upper| (upper, (self.observations.project(upper), Abstraction::default())))
            .collect()
    }

    /// K Means++ implementation yields initial histograms. Abstractions are random and require uniqueness.
    #[rustfmt::skip]
    fn lift_abstractions(&self) -> HashMap<Abstraction, (Histogram, Histogram)> {
        // 0. Initialize data structures
        let mut initials = Vec::new();
        let ref mut histograms = self.observations.values().map(|(histogram, _)| histogram);
        let ref mut rng = rand::thread_rng();
        use rand::distributions::Distribution;
        use rand::distributions::WeightedIndex;
        use rand::seq::SliceRandom;
        // 1. Choose 1st centroid randomly from the dataset
        let sample = histograms
            .collect::<Vec<&Histogram>>()
            .choose(rng)
            .expect("non-empty lower observations")
            .to_owned()
            .clone();
        initials.push(sample);
        // 2. Choose nth centroid with probability proportional to squared distance of nearest neighbors
        const K: usize = 100;
        while initials.len() < K {
            let distances = histograms
                .map(|histogram| initials
                    .iter()
                    .map(|initial| self.metric.emd(initial, histogram))
                    .min_by(|a, b| a.partial_cmp(b).unwrap())
                    .expect("find minimum")
                )
                .map(|min| min * min)
                .collect::<Vec<f32>>();
            let choice = WeightedIndex::new(distances)
                .expect("valid weights")
                .sample(rng);
            let sample = histograms
                .nth(choice)
                .expect("shared index with lowers")
                .clone();
            initials.push(sample);
        }
        // 3. Collect histograms and label with arbitrary (random) Abstractions
        initials
            .into_iter()
            .map(|mean| (Abstraction::random(), (mean, Histogram::default())))
            .collect::<HashMap<_, _>>()
    }

    /// Generate the  baseline metric between equity bucket abstractions. Keeping the u64->f32 conversion is fine for distance since it preserves distance
    fn bottom_metric() -> HashMap<Pair, f32> {
        let mut metric = HashMap::new();
        for i in 0..Abstraction::EQUITIES as u64 {
            for j in i..Abstraction::EQUITIES as u64 {
                let distance = (i - j) as f32;
                let ref i = Abstraction::from(i);
                let ref j = Abstraction::from(j);
                let index = Pair::from((i, j));
                metric.insert(index, distance);
            }
        }
        metric
    }

    // construct observation -> abstraction map via equity calculations
    async fn bottom_observations() -> HashMap<Observation, (Histogram, Abstraction)> {
        let ref observations = Arc::new(Observation::all(Street::Rive));
        let (tx, rx) = tokio::sync::mpsc::channel::<(Observation, Abstraction)>(1024);
        let consumer = Consumer::new(rx).await;
        let consumer = tokio::spawn(consumer.run());
        let producers = (0..num_cpus::get())
            .map(|i| Producer::new(i, tx.clone(), observations.clone()))
            .map(|p| tokio::spawn(p.run()))
            .collect::<Vec<_>>();
        futures::future::join_all(producers).await;
        consumer.await.expect("equity mapping task completes")
    }

    /// upload to database
    async fn upload(&self) {
        use tokio_postgres::binary_copy::BinaryCopyInWriter;
        use tokio_postgres::types::Type;

        const ROW_TYPE: &'static [Type] = &[Type::INT8, Type::INT8];
        const CENTROID: &'static str = r#" 
            CREATE UNLOGGED TABLE IF NOT EXISTS centroid (
                observation BIGINT PRIMARY KEY,
                abstraction BIGINT,
                street      CHAR(1)
            );
            TRUNCATE TABLE centroid;
            COPY centroid (
                street,
                observation,
                abstraction
            )
            FROM STDIN BINARY FREEZE;
        "#;
        const DISTANCE: &'static str = r#"
            BEGIN;
            CREATE UNLOGGED TABLE IF NOT EXISTS distance (
                xor         BIGINT PRIMARY KEY,
                distance    FLOAT,
                street      CHAR(1)
            );
            TRUNCATE TABLE distance;
            COPY distance (
                xor,
                distance,
                street
            )
            FROM STDIN BINARY FREEZE;
        "#;

        let ref url = std::env::var("DATABASE_URL").expect("DATABASE_URL in environment");
        let (client, connection) = tokio_postgres::connect(url, tokio_postgres::NoTls)
            .await
            .expect("connect to database");
        tokio::spawn(connection);
        client
            .execute("BEGIN", &[])
            .await
            .expect("begin transaction");
        // transaction has begun
        // transaction has begun
        // transaction has begun
        let sink = client
            .copy_in(CENTROID)
            .await
            .expect("get sink for COPY transaction");
        let ref mut writer = BinaryCopyInWriter::new(sink, ROW_TYPE);
        let mut writer = unsafe { std::pin::Pin::new_unchecked(writer) };
        let mut progress = Progress::new();
        // first do centroids
        // first do centroids
        // first do centroids
        for (observation, (_, abstraction)) in self.observations.iter() {
            progress.tick();
            let ref observation = i64::from(observation.clone()); // this copy can be optimized out later
            let ref abstraction = i64::from(abstraction.clone()); // this copy can be optimized out later
            writer
                .as_mut()
                .write(&[observation, abstraction])
                .await
                .expect("write row into heap");
        }
        writer
            .finish()
            .await
            .expect("complete 2.8B rows of COPY transaction");
        // now do distances
        // now do distances
        // now do distances
        let sink = client
            .copy_in(DISTANCE)
            .await
            .expect("get sink for COPY transaction");
        let ref mut writer = BinaryCopyInWriter::new(sink, ROW_TYPE);
        let mut writer = unsafe { std::pin::Pin::new_unchecked(writer) };
        let mut progress = Progress::new();
        // now do distances
        // now do distances
        // now do distances
        for (pair, distance) in self.metric.iter() {
            progress.tick();
            let ref pair = i64::from(pair.clone()); // this copy can be optimized out later
            writer
                .as_mut()
                .write(&[pair, distance])
                .await
                .expect("write row into heap");
        }
        // finally commit
        // finally commit
        // finally commit
        client
            .execute("COMMIT", &[])
            .await
            .expect("commit transaction");
    }
}
