use crate::cards::observation::NodeObservation;
use crate::cards::street::Street;
use crate::clustering::abstraction::NodeAbstraction;
use crate::clustering::consumer::Consumer;
use crate::clustering::histogram::Histogram;
use crate::clustering::metric::Metric;
use crate::clustering::producer::Producer;
use crate::clustering::progress::Progress;
use crate::clustering::projection::Projection;
use crate::clustering::xor::Pair;
use std::collections::BTreeMap;
use std::io::Read;
use std::sync::Arc;

/// KMeans hiearchical clustering. Every Observation is to be clustered with "similar" observations. River cards are the base case, where similarity metric is defined by equity. For each higher layer, we compare distributions of next-layer outcomes. Distances are measured by EMD and unsupervised kmeans clustering is used to cluster similar distributions. Potential-aware imperfect recall!
pub struct Layer {
    street: Street,
    metric: BTreeMap<Pair, f32>, // impl Metric
    distributions: BTreeMap<NodeObservation, (Histogram, NodeAbstraction)>, // impl Projection
    kabstractions: BTreeMap<NodeAbstraction, (Histogram, Histogram)>,
}

impl Layer {
    /// Yield the next layer of abstraction by kmeans clustering. The recursive nature of layer methods encapsulates the hiearchy of learned abstractions via kmeans.
    /// TODO; make this async and persist to database after each layer
    pub fn inner(&self) -> Self {
        let mut inner = Self {
            street: self.street.prev(),
            kabstractions: self.inner_kmeans(),
            metric: self.inner_metric(),
            distributions: self.inner_points(),
        };
        inner.cluster();
        inner
    }

    /// async equity calculations to create initial River layer.
    pub async fn outer() -> Self {
        Self {
            street: Street::Rive,
            metric: Self::outer_metric(),
            kabstractions: BTreeMap::default(),
            distributions: Self::outer_points().await,
        }
    }
    /// Write to file. We'll open a new file for each layer, whatever.
    pub fn upload(self) -> Self {
        println!("writing layer {}", self.street);
        self.truncate();
        self.upload_distance();
        self.upload_centroid();
        self
    }

    /// Number of centroids in k means on inner layer. Loosely speaking, the size of our abstraction space.
    fn k(&self) -> usize {
        match self.street.prev() {
            Street::Turn => 500,
            Street::Flop => 500,
            Street::Pref => 169,
            _ => unreachable!("no other prev"),
        }
    }

    /// Number of kmeans iterations to run on current layer.
    fn t(&self) -> usize {
        match self.street.prev() {
            Street::Turn => 100,
            Street::Flop => 100,
            Street::Pref => 10,
            _ => unreachable!("no other prev"),
        }
    }

    /// Run kmeans iterations.
    /// Presumably, we have been generated by a previous layer, with the exception of Outer == River.
    /// After the base case, we trust that our observations, abstractions, and metric are correctly populated.
    fn cluster(&mut self) {
        assert!(self.kabstractions.len() >= self.k());
        println!("clustering kmeans {} < {}", self.street.prev(), self.street);
        let t = self.t();
        let ref mut progress = Progress::new(t, 10);
        for _ in 0..t {
            for observation in self
                .distributions
                .keys()
                .copied()
                .into_iter()
                .collect::<Vec<_>>()
                .iter()
            {
                // Find the nearest neighbor for the current observation
                // Update the distribution with the new neighbor
                let ref mut neighbor = self.neighbor(observation);
                let ref mut incumbent = self
                    .distributions
                    .get_mut(observation)
                    .expect("in continuations")
                    .1;
                let _ = std::mem::replace(incumbent, neighbor.to_owned());
                // Collect histogram of next-round abstractions
                // Absorb these children into the corresponding k-means centroid
                let ref children = self
                    .distributions
                    .get(observation)
                    .expect("in continuations")
                    .0;
                self.kabstractions
                    .get_mut(neighbor)
                    .expect("kabstractions was initialized with neighbor")
                    .0
                    .absorb(children);
            }
            // swap old and new centroids. prepare for next iteration
            for (_, (old, new)) in self.kabstractions.iter_mut() {
                old.clear();
                std::mem::swap(old, new);
            }
            progress.tick();
        }
    }

    /// find nearest neighbor of a given Observation
    fn neighbor(&self, observation: &NodeObservation) -> NodeAbstraction {
        let mut nearests = f32::MAX;
        let mut neighbor = NodeAbstraction::default();
        let ref histogram = self
            .distributions
            .get(observation)
            .expect("in continuations")
            .0;
        for (centroid, (average, _)) in self.kabstractions.iter() {
            let distance = self.metric.emd(histogram, average);
            if distance < nearests {
                nearests = distance;
                neighbor = centroid.to_owned();
            }
        }
        neighbor
    }

    /// Compute the metric of the next innermost layer. Take outer product of centroid histograms over measure.
    fn inner_metric(&self) -> BTreeMap<Pair, f32> {
        println!("computing metric {} < {}", self.street.prev(), self.street);
        let ref centroids = self.kabstractions;
        let mut metric = BTreeMap::new();
        for (i, (x, _)) in centroids.iter().enumerate() {
            for (j, (y, _)) in centroids.iter().enumerate() {
                if i > j {
                    let index = Pair::from((x, y));
                    let ref x = centroids.get(x).expect("in centroids").0;
                    let ref y = centroids.get(y).expect("in centroids").0;
                    let distance = self.metric.emd(x, y);
                    metric.insert(index, distance);
                }
            }
        }
        metric
    }

    /// Generate all possible obersvations of the next innermost layer.
    /// Assign them to arbitrary abstractions. They will be overwritten during kmeans iterations.
    /// Base case is River which comes from equity bucket calculation.
    fn inner_points(&self) -> BTreeMap<NodeObservation, (Histogram, NodeAbstraction)> {
        println!("projecting {} < {}", self.street.prev(), self.street);
        NodeObservation::all(self.street.prev())
            .into_iter()
            .map(|inner| {
                (
                    inner,
                    (
                        self.distributions.project(inner),
                        NodeAbstraction::default(),
                    ),
                )
            })
            .collect()
    }

    /// K Means++ implementation yields initial histograms
    /// Abstraction labels are random and require uniqueness.
    fn inner_kmeans(&self) -> BTreeMap<NodeAbstraction, (Histogram, Histogram)> {
        println!("choosing means {} < {}", self.street.prev(), self.street);
        use rand::distributions::Distribution;
        use rand::distributions::WeightedIndex;
        use rand::seq::SliceRandom;
        use rand::SeedableRng;
        // 0. Initialize data structures
        let mut kmeans = Vec::new();
        // TOOD histograms is empty a la "src/clustering/layer.rs:180:18"
        // TOOD histograms is empty a la "src/clustering/layer.rs:180:18"
        // TOOD histograms is empty a la "src/clustering/layer.rs:180:18"
        // TOOD histograms is empty a la "src/clustering/layer.rs:180:18"
        let ref mut histograms = self.distributions.values().map(|(histogram, _)| histogram);
        let ref mut rng = rand::rngs::StdRng::seed_from_u64(self.street as u64);
        // 1. Choose 1st centroid randomly from the dataset
        let sample = histograms
            .collect::<Vec<&Histogram>>()
            .choose(rng)
            .expect("non-empty lower observations")
            .to_owned()
            .clone();
        kmeans.push(sample);
        // 2. Choose nth centroid with probability proportional to squared distance of nearest neighbors
        while kmeans.len() < self.k() {
            let distances = histograms
                .map(|histogram| {
                    kmeans
                        .iter()
                        .map(|initial| self.metric.emd(initial, histogram))
                        .min_by(|a, b| a.partial_cmp(b).unwrap())
                        .expect("find minimum")
                })
                .map(|min| min * min)
                .collect::<Vec<f32>>();
            let choice = WeightedIndex::new(distances)
                .expect("valid weights array")
                .sample(rng);
            let sample = histograms
                .nth(choice)
                .expect("shared index with lowers")
                .to_owned();
            kmeans.push(sample);
        }
        // 3. Collect histograms and label with arbitrary (random) Abstractions
        kmeans
            .into_iter()
            .map(|mean| (NodeAbstraction::random(), (mean, Histogram::default())))
            .collect::<BTreeMap<_, _>>()
    }

    /// Generate the  baseline metric between equity bucket abstractions. Keeping the u64->f32 conversion is fine for distance since it preserves distance
    fn outer_metric() -> BTreeMap<Pair, f32> {
        println!("calculating equity bucket metric");
        let mut metric = BTreeMap::new();
        for i in 0..NodeAbstraction::EQUITIES as u64 {
            for j in i..NodeAbstraction::EQUITIES as u64 {
                let distance = (j - i) as f32;
                let ref i = NodeAbstraction::from(i);
                let ref j = NodeAbstraction::from(j);
                let index = Pair::from((i, j));
                metric.insert(index, distance);
            }
        }
        metric
    }

    // construct observation -> abstraction map via equity calculations
    async fn outer_points() -> BTreeMap<NodeObservation, (Histogram, NodeAbstraction)> {
        println!("calculating equity bucket observations");
        let ref observations = Arc::new(NodeObservation::all(Street::Rive));
        let (tx, rx) = tokio::sync::mpsc::channel::<(NodeObservation, NodeAbstraction)>(1024);
        let consumer = Consumer::new(rx);
        let consumer = tokio::spawn(consumer.run());
        let producers = (0..num_cpus::get())
            .map(|i| Producer::new(i, tx.clone(), observations.clone()))
            .map(|p| tokio::spawn(p.run()))
            .collect::<Vec<_>>();
        std::mem::drop(tx);
        futures::future::join_all(producers).await;
        consumer.await.expect("equity mapping task completes")
    }
}

/*
persistence methods
*/
impl Layer {
    /// Truncate the files
    fn truncate(&self) {
        std::fs::remove_file(format!("centroid_{}.bin", self.street)).ok();
        std::fs::remove_file(format!("distance_{}.bin", self.street)).ok();
    }

    /// Write centroid data to a file
    fn upload_centroid(&self) {
        let mut file =
            std::fs::File::create(format!("centroid_{}.bin", self.street)).expect("create file");
        let mut progress = Progress::new(self.distributions.len(), 10_000_000);
        for (observation, (_, abstraction)) in self.distributions.iter() {
            use std::io::Write;
            let obs = i64::from(*observation) as u64;
            let abs = i64::from(*abstraction) as u64;
            let ref bytes = [obs.to_le_bytes(), abs.to_le_bytes()].concat();
            file.write_all(bytes).expect("write to file");
            progress.tick();
        }
    }

    /// Write distance data to a file
    fn upload_distance(&self) {
        let mut file =
            std::fs::File::create(format!("distance_{}.bin", self.street)).expect("create file");
        let mut progress = Progress::new(self.metric.len(), 1_000);
        for (pair, distance) in self.metric.iter() {
            use std::io::Write;
            let pair = i64::from(*pair) as u64;
            let distance = f64::from(*distance);
            let ref bytes = [pair.to_le_bytes(), distance.to_le_bytes()].concat();
            file.write_all(bytes).expect("write to file");
            progress.tick();
        }
    }

    /// read centroid data from a file  
    pub fn download_centroid(street: Street) -> BTreeMap<NodeObservation, NodeAbstraction> {
        let mut map = BTreeMap::new();
        let file = std::fs::File::open(format!("centroid_{}.bin", street)).expect("file open");
        let ref mut reader = std::io::BufReader::with_capacity(BUFFER, file);
        let ref mut buffer = [0u8; 16];
        while reader.read_exact(buffer).is_ok() {
            let obs_u64 = u64::from_le_bytes(buffer[0..8].try_into().unwrap());
            let abs_u64 = u64::from_le_bytes(buffer[8..16].try_into().unwrap());
            let observation = NodeObservation::from(obs_u64 as i64);
            let abstraction = NodeAbstraction::from(abs_u64 as i64);
            map.insert(observation, abstraction);
        }
        map
    }

    /// read distance data from a file
    pub fn download_distance(street: Street) -> BTreeMap<Pair, f32> {
        let mut map = BTreeMap::new();
        let file = std::fs::File::open(format!("distance_{}.bin", street)).expect("file open");
        let ref mut reader = std::io::BufReader::with_capacity(BUFFER, file);
        let ref mut buffer = [0u8; 12];
        while reader.read_exact(buffer).is_ok() {
            let pair_u64 = u64::from_le_bytes(buffer[0..08].try_into().unwrap());
            let dist_f64 = f64::from_le_bytes(buffer[8..16].try_into().unwrap());
            let pair = Pair::from(pair_u64 as i64);
            let distance = dist_f64 as f32;
            map.insert(pair, distance);
        }
        map
    }
}

const BUFFER: usize = 1024 * 1024;
