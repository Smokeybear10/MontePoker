use super::histogram::Histogram;
use super::metric::Metric;
use super::projection::Projection;
use super::xor::Pair;
use crate::cards::observation::Observation;
use crate::cards::street::Street;
use crate::clustering::abstraction::Abstraction;
use crate::clustering::bottom::consumer::Consumer;
use crate::clustering::bottom::producer::Producer;
use std::collections::HashMap;
use std::sync::Arc;

pub struct Layer {
    street: Street,
    metric: HashMap<Pair, f32>,
    observations: HashMap<Observation, (Histogram, Abstraction)>,
    abstractions: HashMap<Abstraction, (Histogram, Histogram)>,
}

impl Layer {
    /// async download from database to create initial River layer.
    pub async fn bottom() -> Self { 
        Self {
            street: Street::Rive,
            metric: Self::lower_metric(),
            observations: Self::lower_observations().await,
            abstractions: HashMap::default(),
        } 
    }

    /// Yield the next layer of abstraction by kmeans clustering
    /// TODO; make this async and persist to database after each layer
    pub async fn raise(self) -> Self {
        let mut next = Self {
            street: self.street.prev(),
            metric: self.raise_metric(),
            observations: self.raise_observations(),
            abstractions: self.raise_abstractions(),
        };
        next.kmeans(100);
        next
    }

    /// Run kmeans iterations.
    /// Presumably, we have been generated by a previous layer, with the exception of Bottom == River.
    /// After the base case, we trust that our observations, abstractions, and metric are correctly populated.
    fn kmeans(&mut self, iterations: usize) {
        for _ in 0..iterations {
            for (_, (data, last)) in self.observations.iter_mut() {
                let mut nearests = f32::MAX;
                let mut neighbor = Abstraction::default();
                for (abstraction, (mean, _)) in self.abstractions.iter_mut() {
                    let distance = self.metric.emd(data, mean);
                    if distance < nearests {
                        nearests = distance;
                        neighbor = abstraction.clone();
                    }
                }
                self.abstractions
                    .get_mut(&neighbor)
                    .expect("key from iteration, not default")
                    .0
                    .absorb(data);
                let _ = std::mem::replace(last, neighbor);
            }
        }
    }

    /// Calculate and return the metric using EMD distances between abstractions 
    fn raise_metric(&self) -> HashMap<Pair, f32> {
        let ref centroids = self.abstractions;
        let mut metric = HashMap::new();
        for (i, (x, _)) in centroids.iter().enumerate() {
            for (j, (y, _)) in centroids.iter().enumerate() {
                if i > j {
                    let index = Pair::from((x, y));
                    let ref x = centroids.get(x).expect("kmeans histogram").0;
                    let ref y = centroids.get(y).expect("kmeans histogram").0;
                    let distance = self.metric.emd(x, y);
                    metric.insert(index, distance);
                }
            }
        }
        metric
    }

    /// Generate all possible obersvations. Assign them to arbitrary abstractions. They will be overwritten during kmeans iterations. We start from River which comes from database from equity abstractions.
    #[rustfmt::skip]
    fn raise_observations(&self) -> HashMap<Observation, (Histogram, Abstraction)> {
        Observation::all(self.street.prev())
            .into_iter()
            .map(|upper| (upper, (self.observations.project(upper), Abstraction::default())))
            .collect()
    }
    
    #[rustfmt::skip]
    /// K Means++ implementation yields initial histograms. Abstractions are random and require uniqueness.
    fn raise_abstractions(&self) -> HashMap<Abstraction, (Histogram, Histogram)> {
        // 0. Initialize data structures
        let mut initials = Vec::new();
        let ref mut histograms = self.observations.values().map(|(histogram, _)| histogram);
        let ref mut rng = rand::thread_rng();
        use rand::distributions::Distribution;
        use rand::distributions::WeightedIndex;
        use rand::seq::SliceRandom;
        // 1. Choose 1st centroid randomly from the dataset
        let sample = histograms
            .collect::<Vec<&Histogram>>()
            .choose(rng)
            .expect("non-empty lower observations")
            .to_owned()
            .clone();
        initials.push(sample);
        // 2. Choose nth centroid with probability proportional to squared distance of nearest neighbors
        const K: usize = 100;
        while initials.len() < K {
            let distances = histograms
                .map(|histogram| initials
                    .iter()
                    .map(|initial| self.metric.emd(initial, histogram))
                    .min_by(|a, b| a.partial_cmp(b).unwrap())
                    .expect("find minimum")
                )
                .map(|min| min * min)
                .collect::<Vec<f32>>();
            let choice = WeightedIndex::new(distances)
                .expect("valid weights")
                .sample(rng);
            let sample = histograms
                .nth(choice)
                .expect("shared index with lowers")
                .clone();
            initials.push(sample);
        }
        // 3. Collect histograms and label with arbitrary (random) Abstractions
        initials
            .into_iter()
            .map(|mean| (Abstraction::random(), (mean, Histogram::default())))
            .collect::<HashMap<_, _>>()
    }

    /// Generate the  baseline metric between equity bucket abstractions. Keeping the u64->f32 conversion is fine for distance since it preserves distance
    fn lower_metric() -> HashMap<Pair, f32> {
        let mut metric = HashMap::new();
        for i in 0..Abstraction::EQUITIES as u64 {
            for j in i..Abstraction::EQUITIES as u64 {
                let distance = (i - j) as f32;
                let ref i = Abstraction::from(i);
                let ref j = Abstraction::from(j);
                let index = Pair::from((i, j));
                metric.insert(index, distance);
            }
        }
        metric
    }

    // construct observation -> abstraction map via equity calculations
    async fn lower_observations() -> HashMap<Observation, (Histogram, Abstraction)> {
        let ref observations = Arc::new(Observation::all(Street::Rive));
        let (tx, rx) = tokio::sync::mpsc::channel::<(Observation, Abstraction)>(1024);
        let consumer = Consumer::new(rx).await;
        let consumer = tokio::spawn(consumer.run());
        let producers = (0..num_cpus::get())
            .map(|i| Producer::new(i, tx.clone(), observations.clone()))
            .map(|p| tokio::spawn(p.run()))
            .collect::<Vec<_>>();
        futures::future::join_all(producers).await;
        consumer.await.expect("equity mapping task completes")
    }
}
